{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setting and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=48, do_augment=True, dq_size=6, epochs=100, gpu_id=5, image_dir='/data/seanyu/cat_dog/dataset/', image_size=(256, 256, 3), lr=0.00017, model_file_name='model.h5', n_batch=100, n_classes=2, n_threads=4, save_dir='./result', train_ratio=0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from time import sleep\n",
    "from tqdm import tqdm # if use notebook\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Event\n",
    "import queue\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import random\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--gpu_id', default=5)\n",
    "parser.add_argument('--image_dir', default=\"/data/seanyu/cat_dog/dataset/\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "parser.add_argument('--batch_size', default=48, type=int)\n",
    "parser.add_argument('--do_augment', default=True, type = bool)\n",
    "parser.add_argument('--epochs', default=100, type=int)\n",
    "parser.add_argument('--lr', default=0.00017, type=float)\n",
    "parser.add_argument('--image_size', default=(256,256,3), type = int)\n",
    "parser.add_argument('--n_classes', default=2, type = int)\n",
    "parser.add_argument('--n_batch', default=100, type = int)\n",
    "parser.add_argument('--train_ratio', default=0.9, type = float)\n",
    "parser.add_argument('--model_file_name', default = 'model.h5')\n",
    "parser.add_argument('--n_threads', default = 4, type = int)\n",
    "parser.add_argument('--dq_size', default = 6, type = int)\n",
    "\n",
    "FLAGS = parser.parse_args([])\n",
    "print(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.gpu_id = \"6\"\n",
    "FLAGS.image_dir = \"/data/seanyu/cat_dog/dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check path and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(FLAGS.gpu_id)\n",
    "import tensorflow as tf\n",
    "\n",
    "if not os.path.exists(FLAGS.save_dir):\n",
    "    os.makedirs(FLAGS.save_dir)\n",
    "\n",
    "model_dir = FLAGS.save_dir + '/model'\n",
    "\n",
    "\"\"\"  Get data \"\"\"\n",
    "d_train = FLAGS.image_dir + '/train/'\n",
    "d_test = FLAGS.image_dir + '/test1/'\n",
    "\n",
    "image_train_list = glob.glob(d_train + '*.jpg')\n",
    "image_test_list = glob.glob(d_test + '*.jpg')\n",
    "\n",
    "df_train = pd.DataFrame({'img_path': image_train_list})\n",
    "df_test = pd.DataFrame({'img_path': image_test_list})\n",
    "\n",
    "df_train['cate'] = df_train.img_path.apply(os.path.basename)\n",
    "df_train['cate'] = [i.split(\".\")[0] for i in list(df_train.cate)]\n",
    "df_train.cate = df_train.cate.replace({'dog': 0, 'cat': 1})\n",
    "\n",
    "nb_epoch = FLAGS.epochs\n",
    "\n",
    "df_train_0, df_val_0 = train_test_split(df_train[df_train['cate'] == 0], test_size = 1-FLAGS.train_ratio)\n",
    "df_train_1, df_val_1 = train_test_split(df_train[df_train['cate'] == 1], test_size = 1-FLAGS.train_ratio)\n",
    "\n",
    "df_val = pd.concat((df_val_0, df_val_1)).reset_index(drop = True)\n",
    "\n",
    "del df_val_0, df_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import imgaug as ia\n",
    "    from imgaug import augmenters as iaa\n",
    "except:\n",
    "    print(\"Import Error, Please make sure you have imgaug\")\n",
    "        \n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append(\"/mnt/deep-learning/usr/seanyu/common_tools/\")\n",
    "    from customized_imgaug_func import keypoint_func, img_channelswap\n",
    "except:\n",
    "    print(\"Warning, if you used customized imgaug function\")\n",
    "    \n",
    "class Augmentation_Setup(object):  \n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "    lesstimes = lambda aug: iaa.Sometimes(0.2, aug)\n",
    "    \n",
    "    augmentation = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5, name=\"FlipLR\"),\n",
    "        iaa.Flipud(0.5, name=\"FlipUD\"),\n",
    "        iaa.ContrastNormalization((0.8, 1.2), name = \"Contrast\"),\n",
    "        iaa.Add((-15, 15), per_channel = 0.5),\n",
    "        iaa.OneOf([iaa.Multiply((0.8, 1.2), per_channel = 0.5, name = \"Multiply\"),\n",
    "                   iaa.AddToHueAndSaturation((-15,30),name = \"Hue\"),\n",
    "                  ]),\n",
    "        sometimes(iaa.GaussianBlur((0, 1.0), name=\"GaussianBlur\")),\n",
    "        iaa.OneOf([iaa.Affine(rotate = 90),\n",
    "                   iaa.Affine(rotate = 180),\n",
    "                   iaa.Affine(rotate = 270)]),\n",
    "        sometimes(iaa.Affine(\n",
    "                    scale = (0.8,1.2),\n",
    "                    #translate_percent = (-0.2, 0.2),\n",
    "                    #rotate = (-15, 15),\n",
    "                    mode = 'wrap'\n",
    "                    )),\n",
    "        iaa.OneOf([iaa.AdditiveGaussianNoise(scale=0.05*255, name=\"Noise\"),\n",
    "               iaa.CoarseDropout((0.05, 0.15), size_percent=(0.01, 0.05), name = 'Cdrop')\n",
    "               ]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDataset():\n",
    "    def __init__(self, df_list, class_id, n_classes, f_input_preproc, image_size=(256,256,3), onehot=True, augmentation=None):\n",
    "        \n",
    "        self.df_list = df_list\n",
    "        self.class_id = class_id\n",
    "        self.n_classes = n_classes\n",
    "        self.preproc = f_input_preproc\n",
    "        self.image_size = image_size\n",
    "        self.onehot = onehot\n",
    "        self.aug = augmentation\n",
    "        \n",
    "        ## Init ##\n",
    "        self.df_list = self.df_list.sample(frac=1.).reset_index(drop=True)\n",
    "        self.current_index = 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = self.load_image(img_path=self.df_list.iloc[self.current_index]['img_path'], image_size=self.image_size)\n",
    "        \n",
    "        if self.aug is not None:\n",
    "            img = self.aug.augment_image(img)\n",
    "            \n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        if self.preproc is not None:\n",
    "            img = self.preproc(img)\n",
    "        \n",
    "        label = self.class_id\n",
    "        if self.onehot:\n",
    "             label = tf.keras.utils.to_categorical(label, num_classes=self.n_classes)\n",
    "        \n",
    "        self.current_index = (self.current_index + 1) % len(self.df_list)\n",
    "        return img, label\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.__getitem__(idx=self.current_index)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_image(img_path, image_size):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (image_size[0], image_size[1]))\n",
    "        return img\n",
    "    \n",
    "class Customized_dataloader():\n",
    "    \"\"\"\n",
    "    1. Compose multiple generators together\n",
    "    2. Make this composed generator into multi-processing function\n",
    "    \"\"\"\n",
    "    def __init__(self, list_dataset, batch_size_per_dataset=16, queue_size=128, num_workers=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - list_dataset: put generator object as list [gen1, gen2, ...]\n",
    "            - batch_size_per_dataset: bz for each generator (total_batch_size/n_class)\n",
    "            - queue_size: queue size\n",
    "            - num_workers: start n workers to get data\n",
    "        \n",
    "        Action: Call with next\n",
    "        \"\"\"\n",
    "        self.list_dataset = list_dataset\n",
    "        self.batch_size_per_dataset = batch_size_per_dataset\n",
    "        self.sample_queue = mp.Queue(maxsize = queue_size)\n",
    "        \n",
    "        self.jobs = num_workers\n",
    "        self.events = list()\n",
    "        self.workers = list()\n",
    "        for i in range(num_workers):\n",
    "            event = Event()\n",
    "            work = mp.Process(target = enqueue, args = (self.sample_queue, event, self.compose_data))\n",
    "            work.daemon = True\n",
    "            work.start()\n",
    "            self.events.append(event)\n",
    "            self.workers.append(work)\n",
    "        print(\"workers ready\")\n",
    "        \n",
    "    def __next__(self):\n",
    "        return self.sample_queue.get()\n",
    "    \n",
    "    def compose_data(self):\n",
    "        while True:\n",
    "            imgs, labels = [], []\n",
    "            for z in range(self.batch_size_per_dataset):\n",
    "                data = [next(i) for i in self.list_dataset]\n",
    "                img, label = zip(*data)\n",
    "                imgs.append(np.array(img))\n",
    "                labels.append(np.array(label))\n",
    "            yield np.concatenate(imgs), np.concatenate(labels)\n",
    "    \n",
    "    def stop_worker(self):\n",
    "        for t in self.events:\n",
    "            t.set()\n",
    "        for i, t in enumerate(self.workers):\n",
    "            t.join(timeout = 1)\n",
    "        print(\"all_worker_stop\")\n",
    "\n",
    "# ----- #\n",
    "def enqueue(queue, stop, gen_func):\n",
    "    gen = gen_func()\n",
    "    while True:\n",
    "        if stop.is_set():\n",
    "            return\n",
    "        queue.put(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(img):\n",
    "    return (img - img.min()) / (img.max() - img.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_RESNET_PREPROC = False\n",
    "dog_train = GetDataset(df_list=df_train[df_train['cate'] == 0],\n",
    "                       class_id=0, n_classes=2,\n",
    "                       f_input_preproc=preproc if not USE_RESNET_PREPROC else tf.keras.applications.resnet50.preprocess_input,\n",
    "                       augmentation=Augmentation_Setup.augmentation, \n",
    "                       onehot= True, \n",
    "                       image_size=(256,256,3))\n",
    "\n",
    "cat_train = GetDataset(df_list=df_train[df_train['cate'] == 1], \n",
    "                       class_id=1, n_classes=2, \n",
    "                       f_input_preproc=preproc if not USE_RESNET_PREPROC else tf.keras.applications.resnet50.preprocess_input,\n",
    "                       augmentation=Augmentation_Setup.augmentation, \n",
    "                       onehot= True, \n",
    "                       image_size=(256,256,3))\n",
    "\n",
    "dog_valid = GetDataset(df_list=df_val[df_val['cate'] == 0], \n",
    "                       class_id=0, n_classes=2,\n",
    "                       f_input_preproc=preproc if not USE_RESNET_PREPROC else tf.keras.applications.resnet50.preprocess_input,\n",
    "                       augmentation=None, \n",
    "                       onehot= True, \n",
    "                       image_size=(256,256,3))\n",
    "\n",
    "cat_valid = GetDataset(df_list=df_val[df_val['cate'] == 1], \n",
    "                       class_id=1, n_classes=2, \n",
    "                       f_input_preproc=preproc if not USE_RESNET_PREPROC else tf.keras.applications.resnet50.preprocess_input,\n",
    "                       augmentation=None, \n",
    "                       onehot= True, \n",
    "                       image_size=(256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workers ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_worker_stop\n",
      "(480, 256, 256, 3)\n",
      "(480, 2)\n",
      "[240. 240.]\n"
     ]
    }
   ],
   "source": [
    "valid_gen = Customized_dataloader([dog_valid, cat_valid], batch_size_per_dataset=FLAGS.batch_size//2, num_workers=2, queue_size=10)\n",
    "x_val, y_val = [], []\n",
    "for _ in tqdm(range(10)):\n",
    "    a,b = next(valid_gen)\n",
    "    x_val.append(a)\n",
    "    y_val.append(b)\n",
    "x_val = np.concatenate(x_val)\n",
    "y_val = np.concatenate(y_val)\n",
    "valid_gen.stop_worker()\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Use keras, official resnet\\nimport keras\\nclass Build_FunctionalModel():\\n    def __init__(self, input_shape, classes, backbone=\\'resnet50\\', use_pretrain=False):\\n        self.input_layer = keras.layers.Input(shape=input_shape, name=\"input\")\\n        graph_pool = keras.applications.ResNet50(input_tensor=self.input_layer, include_top=False)\\n        gap = keras.layers.GlobalAveragePooling2D()(graph_pool.output)\\n        self.logit = keras.layers.Dense(units=classes, name=\"logit\")(gap)\\n        self.out = keras.layers.Activation(\"softmax\", name=\"output\")(self.logit)\\n\\n    def build(self):\\n        return keras.models.Model(inputs=self.input_layer, outputs=self.out)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "sys.path.append(\"/mnt/deep-learning/usr/seanyu/lab_mldl_tools/models/\")\n",
    "from tf_resnet.model import set_custom_objects, resnet_graph\n",
    "\n",
    "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/'\\\n",
    "                         'releases/download/v0.2/'\\\n",
    "                         'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\"\"\"\n",
    "class Build_FunctionalModel():\n",
    "    def __init__(self, input_shape, classes, backbone='resnet50', use_pretrain=False):\n",
    "        input_layer = tf.keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "        self.pretrain_modules, stage_layers = resnet_graph(input_tensor=input_layer, \n",
    "                                                           architecture=backbone, \n",
    "                                                           train_bn=True, norm_use='bn')\n",
    "        if use_pretrain:\n",
    "            weight_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', \n",
    "                                   TF_WEIGHTS_PATH_NO_TOP, \n",
    "                                   cache_subdir=\"models\", \n",
    "                                   md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "            self.pretrain_modules.load_weights(weight_path)\n",
    "\n",
    "        self.out = tf.keras.layers.Dense(units=classes, name=\"output\")(self.pretrain_modules.output)\n",
    "    \n",
    "    def build(self):\n",
    "        return tf.keras.Model(inputs=[self.pretrain_modules.input], outputs=[self.out])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Use tf.keras, official resnet\n",
    "class Build_FunctionalModel():\n",
    "    def __init__(self, input_shape, classes, backbone='resnet50', use_pretrain=False):\n",
    "        \n",
    "        self.input_layer = tf.keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "        graph_pool = tf.keras.applications.ResNet50(input_tensor=self.input_layer, include_top=False)\n",
    "        gap = tf.keras.layers.GlobalAveragePooling2D()(graph_pool.output)\n",
    "        self.logit = tf.keras.layers.Dense(units=classes, name=\"logit\")(gap)\n",
    "        self.out = tf.keras.layers.Activation(\"softmax\", name=\"output\")(self.logit)\n",
    "        \n",
    "        \n",
    "        #self.graph_pool = tf.keras.applications.resnet50.ResNet50(input_shape=input_shape, include_top=False)#weights='imagenet')\n",
    "        #gap = tf.keras.layers.GlobalAveragePooling2D()(self.graph_pool.output)\n",
    "        #self.out = tf.keras.layers.Dense(units=classes, name=\"output\", activation=\"softmax\")(gap)\n",
    "    def build(self):\n",
    "        #return tf.keras.models.Model(inputs=self.graph_pool.input, outputs=self.out)\n",
    "        return tf.keras.models.Model(inputs=self.input_layer, outputs=self.out)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Use keras, official resnet\n",
    "import keras\n",
    "class Build_FunctionalModel():\n",
    "    def __init__(self, input_shape, classes, backbone='resnet50', use_pretrain=False):\n",
    "        self.input_layer = keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "        graph_pool = keras.applications.ResNet50(input_tensor=self.input_layer, include_top=False)\n",
    "        gap = keras.layers.GlobalAveragePooling2D()(graph_pool.output)\n",
    "        self.logit = keras.layers.Dense(units=classes, name=\"logit\")(gap)\n",
    "        self.out = keras.layers.Activation(\"softmax\", name=\"output\")(self.logit)\n",
    "\n",
    "    def build(self):\n",
    "        return keras.models.Model(inputs=self.input_layer, outputs=self.out)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\"\"\"\n",
    "pretrain_model = tf.keras.applications.resnet50.ResNet50(include_top=False, input_shape=x_val.shape[1:], weights='imagenet')\n",
    "gap = tf.keras.layers.GlobalAveragePooling2D()(pretrain_model.output)\n",
    "model_output = tf.keras.layers.Dense(units=2, activation='softmax', name='output')(gap)\n",
    "model = tf.keras.models.Model(inputs = [pretrain_model.input], outputs = [model_output])\n",
    "\"\"\"\n",
    "\n",
    "model = Build_FunctionalModel(input_shape=[256, 256, 3], classes=2, backbone=\"resnet50\", use_pretrain=True)\n",
    "model = model.build()\n",
    "\n",
    "optim = tf.train.AdamOptimizer(learning_rate=FLAGS.lr) #tf.keras.optimizers.Adam(lr=FLAGS.lr)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              metrics=[\"accuracy\"], \n",
    "              optimizer=optim)\n",
    "\n",
    "\"\"\"\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"], \n",
    "              optimizer=keras.optimizers.Adam(lr=FLAGS.lr))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note Area ###\n",
    "#### tf.keras lab-resnet\n",
    "\n",
    "\n",
    "#### tf.keras official-resnet\n",
    "* loss use tf.keras.losses.categorical_crossentropy / tf.keras.losses.binary_crossentropy will FAIL\n",
    "* loss use tf.losses.softmax_cross_entropy\n",
    "* loss use 'categorical_crossentropy' will PASS and SOSO\n",
    "\n",
    "#### keras\n",
    "1. PASS and GOOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = Customized_dataloader([dog_train, cat_train], \n",
    "                                  batch_size_per_dataset=FLAGS.batch_size//2, \n",
    "                                  num_workers=4, queue_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 48s 477ms/step - loss: 0.1683 - acc: 0.9498 - val_loss: 2.6755 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 47s 465ms/step - loss: 0.1667 - acc: 0.9517 - val_loss: 0.8784 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 0.1357 - acc: 0.9583 - val_loss: 0.9400 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 47s 466ms/step - loss: 0.1176 - acc: 0.9602 - val_loss: 0.7147 - val_acc: 0.4917\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 46s 464ms/step - loss: 0.1450 - acc: 0.9535 - val_loss: 0.8221 - val_acc: 0.5083\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 46s 465ms/step - loss: 0.0930 - acc: 0.9675 - val_loss: 0.5935 - val_acc: 0.6333\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 46s 465ms/step - loss: 0.1361 - acc: 0.9629 - val_loss: 0.3012 - val_acc: 0.8708\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 0.1251 - acc: 0.9604 - val_loss: 0.4568 - val_acc: 0.8125\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 46s 464ms/step - loss: 0.1062 - acc: 0.9694 - val_loss: 0.2063 - val_acc: 0.9208\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 47s 465ms/step - loss: 0.1099 - acc: 0.9633 - val_loss: 0.2826 - val_acc: 0.8750\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 46s 465ms/step - loss: 0.1162 - acc: 0.9692 - val_loss: 0.1813 - val_acc: 0.9167\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 47s 468ms/step - loss: 0.0987 - acc: 0.9669 - val_loss: 0.2179 - val_acc: 0.9292\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 0.1057 - acc: 0.9675 - val_loss: 0.5388 - val_acc: 0.8625\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 0.0999 - acc: 0.9660 - val_loss: 0.5291 - val_acc: 0.8083\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 47s 466ms/step - loss: 0.0988 - acc: 0.9652 - val_loss: 0.0897 - val_acc: 0.9583\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 47s 468ms/step - loss: 0.1058 - acc: 0.9688 - val_loss: 0.3508 - val_acc: 0.8750\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 46s 464ms/step - loss: 0.1129 - acc: 0.9623 - val_loss: 0.8491 - val_acc: 0.8042\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 47s 466ms/step - loss: 0.1062 - acc: 0.9648 - val_loss: 0.1941 - val_acc: 0.9250\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 46s 464ms/step - loss: 0.1076 - acc: 0.9654 - val_loss: 0.2127 - val_acc: 0.9167\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 0.1225 - acc: 0.9575 - val_loss: 0.2833 - val_acc: 0.9042\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 0.0962 - acc: 0.9704 - val_loss: 0.2376 - val_acc: 0.9042\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 0.1100 - acc: 0.9606 - val_loss: 0.2174 - val_acc: 0.9250\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 0.1320 - acc: 0.9552 - val_loss: 0.1346 - val_acc: 0.9417\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 0.0885 - acc: 0.9690 - val_loss: 0.2865 - val_acc: 0.9250\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 47s 465ms/step - loss: 0.1305 - acc: 0.9577 - val_loss: 0.2048 - val_acc: 0.9083\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 0.1162 - acc: 0.9598 - val_loss: 0.1530 - val_acc: 0.9250\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 0.1120 - acc: 0.9635 - val_loss: 0.3235 - val_acc: 0.8792\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 46s 463ms/step - loss: 0.1137 - acc: 0.9610 - val_loss: 0.2458 - val_acc: 0.9083\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 46s 459ms/step - loss: 0.1259 - acc: 0.9583 - val_loss: 0.2338 - val_acc: 0.9250\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 46s 464ms/step - loss: 0.1247 - acc: 0.9558 - val_loss: 0.1901 - val_acc: 0.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cb_list = [tf.keras.callbacks.ReduceLROnPlateau(factor=0.5,\n",
    "                                                patience=4,\n",
    "                                                min_lr=1e-12),\n",
    "           tf.keras.callbacks.EarlyStopping(min_delta = 1e-4, \n",
    "                                            patience= 50)\n",
    "          ]\n",
    "\n",
    "model.fit_generator(train_gen,\n",
    "                    epochs=FLAGS.epochs,\n",
    "                    steps_per_epoch=FLAGS.n_batch, \n",
    "                    validation_data=(x_val, y_val),\n",
    "                    #callbacks=cb_list\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {
    "6b1438b3075f49289cfcf03a4fce2ccb": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "ab7848b490e5454e9a42f439a6ef6b31": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "e0e3b0d66b1e47c4ade6c276bacc5c55": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
