{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setting and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, do_augment=True, dq_size=6, epochs=50, gpu_id=5, image_dir='/data/seanyu/cat_dog/dataset/', image_size=(256, 256, 3), lr=0.0001, model_file_name='tmp_nb', n_batch=100, n_classes=2, n_threads=4, save_dir='./result', train_ratio=0.99, use_model_ckpt=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from time import sleep\n",
    "from tqdm import tqdm # if use notebook\n",
    "\n",
    "\n",
    "from threading import Thread, Event, Timer\n",
    "import queue\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import random\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--gpu_id', default=5)\n",
    "parser.add_argument('--image_dir', default=\"/data/seanyu/cat_dog/dataset/\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "parser.add_argument('--batch_size', default=64, type=int)\n",
    "parser.add_argument('--do_augment', default=True, type = bool)\n",
    "parser.add_argument('--epochs', default=50, type=int)\n",
    "parser.add_argument('--lr', default=0.0001, type=float)\n",
    "parser.add_argument('--image_size', default=(256,256,3), type = int)\n",
    "parser.add_argument('--n_classes', default=2, type = int)\n",
    "parser.add_argument('--n_batch', default=100, type = int)\n",
    "parser.add_argument('--train_ratio', default=0.99, type = float)\n",
    "parser.add_argument('--use_model_ckpt', default = None, type = str)\n",
    "parser.add_argument('--model_file_name', default = 'tmp_nb')\n",
    "parser.add_argument('--n_threads', default = 4, type = int)\n",
    "parser.add_argument('--dq_size', default = 6, type = int)\n",
    "\n",
    "FLAGS = parser.parse_args([])\n",
    "print(FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check path and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(FLAGS.gpu_id)\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "if not os.path.exists(FLAGS.save_dir):\n",
    "    os.makedirs(FLAGS.save_dir)\n",
    "\n",
    "model_dir = FLAGS.save_dir + '/model'\n",
    "    \n",
    "graphs_dir = FLAGS.save_dir + '/graphs'\n",
    "if not os.path.exists(graphs_dir):\n",
    "    os.makedirs(graphs_dir)\n",
    "\n",
    "\"\"\"  Get data \"\"\"\n",
    "d_train = FLAGS.image_dir + '/train/'\n",
    "d_test = FLAGS.image_dir + '/test1/'\n",
    "\n",
    "image_train_list = glob.glob(d_train + '*.jpg')\n",
    "image_test_list = glob.glob(d_test + '*.jpg')\n",
    "\n",
    "df_train = pd.DataFrame({'img_path': image_train_list})\n",
    "df_test = pd.DataFrame({'img_path': image_test_list})\n",
    "\n",
    "df_train['cate'] = df_train.img_path.apply(os.path.basename)\n",
    "df_train['cate'] = [i.split(\".\")[0] for i in list(df_train.cate)]\n",
    "df_train.cate = df_train.cate.replace({'dog': 0, 'cat': 1})\n",
    "\n",
    "nb_epoch = FLAGS.epochs\n",
    "\n",
    "df_train_0, df_val_0 = train_test_split(df_train[df_train['cate'] == 0], test_size = 1-FLAGS.train_ratio)\n",
    "df_train_1, df_val_1 = train_test_split(df_train[df_train['cate'] == 1], test_size = 1-FLAGS.train_ratio)\n",
    "\n",
    "df_val = pd.concat((df_val_0, df_val_1)).reset_index(drop = True)\n",
    "\n",
    "del df_val_0, df_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([cv2.resize(cv2.cvtColor(cv2.imread(i), cv2.COLOR_BGR2RGB), (256,256)) for i in df_train.img_path], dtype=np.float32)\n",
    "y_train = tf.keras.utils.to_categorical(df_train.cate.values, 2)\n",
    "\n",
    "x_valid = np.array([cv2.resize(cv2.cvtColor(cv2.imread(i), cv2.COLOR_BGR2RGB), (256,256)) for i in df_val.img_path], dtype=np.float32)\n",
    "y_valid = tf.keras.utils.to_categorical(df_val.cate.values, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsometimes = lambda aug: iaa.Sometimes(0.5, aug)\\n\\nseq = iaa.Sequential([\\n    iaa.Fliplr(0.5),\\n    iaa.Flipud(0.5),\\n    sometimes(iaa.Add((-10, 10), per_channel=0.5)),\\n    sometimes(iaa.ContrastNormalization((0.4, 0.6)))\\n])\\n\\ndef cv_load_and_resize(x, image_size, is_training = True, do_augment = False, seq = None):\\n    im_w, im_h, im_c = image_size\\n    im = cv2.imread(x)\\n    im = cv2.resize(im, (im_w, im_h))\\n    if do_augment and is_training:\\n        im = seq.augment_image(im)\\n    return im\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    sometimes(iaa.Add((-10, 10), per_channel=0.5)),\n",
    "    sometimes(iaa.ContrastNormalization((0.4, 0.6)))\n",
    "])\n",
    "\n",
    "def cv_load_and_resize(x, image_size, is_training = True, do_augment = False, seq = None):\n",
    "    im_w, im_h, im_c = image_size\n",
    "    im = cv2.imread(x)\n",
    "    im = cv2.resize(im, (im_w, im_h))\n",
    "    if do_augment and is_training:\n",
    "        im = seq.augment_image(im)\n",
    "    return im\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'wrap_pretrain/pretrain_parameters:0' shape=(256, 23519360) dtype=float32_ref>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "wrap_pretrain_1 (Wrap_pretra (None, 1, 1, 2048)        6020956160\n",
      "_________________________________________________________________\n",
      "GAP_Layer (GlobalAveragePool (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 6,020,960,258\n",
      "Trainable params: 6,020,960,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Numbers of Trainable parameters in Wrapped layer: 0 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets as slimNet\n",
    "from resnet import resnet_v2_50\n",
    "import resnet_utils\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "input_holder = tf.keras.layers.Input(shape=[256, 256, 3], name=\"inputs\")\n",
    "\n",
    "# Lambda layer form\n",
    "def lambda_pretrain(x):\n",
    "    with slim.arg_scope(resnet_utils.resnet_arg_scope(batch_norm_decay=0.95)):\n",
    "        net, layers_dict = resnet_v2_50(inputs=x, is_training=True)\n",
    "    \n",
    "    return net\n",
    "\n",
    "# Custom layer form\n",
    "class Wrap_pretrain(tf.keras.layers.Layer):\n",
    "    def __init__(self, input):\n",
    "        super(Wrap_pretrain, self).__init__()\n",
    "        self.tensor_input = input\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        with slim.arg_scope(resnet_utils.resnet_arg_scope(batch_norm_decay=0.95)):\n",
    "            self.net, layers_dict = resnet_v2_50(inputs=self.tensor_input, is_training=tf.keras.backend.learning_phase())\n",
    "        \n",
    "        \"\"\"\n",
    "        total_parameters = 0\n",
    "        for variable in tf.trainable_variables():\n",
    "            # shape is an array of tf.Dimension\n",
    "            shape = variable.get_shape()\n",
    "            #print(shape)\n",
    "            variable_parameters = 1\n",
    "            for dim in shape:\n",
    "                variable_parameters *= dim.value\n",
    "            total_parameters += variable_parameters\n",
    "        \n",
    "        self.kernel = self.add_weight(name='pretrain_parameters',\n",
    "                                       shape=(input_shape[1], total_parameters),\n",
    "                                       initializer='uniform',\n",
    "                                       trainable=True)\n",
    "        print(self.kernel)\n",
    "        \"\"\"\n",
    "        self.kernel = []\n",
    "        for i, layer in enumerate(tf.trainable_variables()):\n",
    "            if i == 0:\n",
    "                w = self.add_weight(name='l'+str(i),\n",
    "                                    shape=(input_shape[]))\n",
    "                self.kernel.append()\n",
    "        \n",
    "        super(Wrap_pretrain, self).build(input_shape)\n",
    "        \n",
    "    \n",
    "    def call(self, input):\n",
    "        return self.net\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple(input_shape)\n",
    "\n",
    "#net = tf.keras.layers.Lambda(lambda_pretrain)(input_holder)\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "\n",
    "net = Wrap_pretrain(input_holder)(input_holder)\n",
    "\n",
    "gap_layer = tf.keras.layers.GlobalAveragePooling2D(name=\"GAP_Layer\")(net)\n",
    "out = tf.keras.layers.Dense(2, name='output', activation='softmax')(gap_layer)\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_holder], outputs=[out])\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"], \n",
    "              optimizer=optimizer)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    update = optimizer.minimize(model.total_loss)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "print(\"Numbers of Trainable parameters in Wrapped layer: %i \" % total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             multiple                  23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Directly use tf.keras.application\n",
    "tf.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "input_holder = tf.keras.layers.Input(shape=[256, 256, 3], name=\"inputs\")\n",
    "pretrain = tf.keras.applications.ResNet50(include_top=False, classes=2, weights=None)(input_holder)\n",
    "gap_layer = tf.keras.layers.Flatten()(pretrain)\n",
    "out = tf.keras.layers.Dense(2, activation='softmax')(gap_layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_holder], outputs=[out])\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"], \n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.001))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 252 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[256,23519360] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: wrap_pretrain/pretrain_parameters/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@wrap_pretrain/pretrain_parameters/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](wrap_pretrain/pretrain_parameters/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'wrap_pretrain/pretrain_parameters/Initializer/random_uniform/RandomUniform', defined at:\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/seanyu/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/seanyu/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/seanyu/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-138-d8fb023f8d40>\", line 63, in <module>\n    net = Wrap_pretrain(input_holder)(input_holder)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/base_layer.py\", line 314, in __call__\n    output = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 699, in __call__\n    self.build(input_shapes)\n  File \"<ipython-input-138-d8fb023f8d40>\", line 43, in build\n    trainable=True)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/base_layer.py\", line 206, in add_weight\n    trainable=trainable)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/training/checkpointable.py\", line 436, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 343, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 770, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 253, in __call__\n    shape, self.minval, self.maxval, dtype, seed=self.seed)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 674, in random_uniform\n    name=name)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[256,23519360] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: wrap_pretrain/pretrain_parameters/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@wrap_pretrain/pretrain_parameters/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](wrap_pretrain/pretrain_parameters/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[256,23519360] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: wrap_pretrain/pretrain_parameters/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@wrap_pretrain/pretrain_parameters/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](wrap_pretrain/pretrain_parameters/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-0183a438bdf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    243\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2797\u001b[0m       \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2799\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2800\u001b[0m     \u001b[0mdata_tensors_to_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2801\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    671\u001b[0m       \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m       \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[256,23519360] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: wrap_pretrain/pretrain_parameters/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@wrap_pretrain/pretrain_parameters/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](wrap_pretrain/pretrain_parameters/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'wrap_pretrain/pretrain_parameters/Initializer/random_uniform/RandomUniform', defined at:\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/seanyu/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/seanyu/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/seanyu/.local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-138-d8fb023f8d40>\", line 63, in <module>\n    net = Wrap_pretrain(input_holder)(input_holder)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/base_layer.py\", line 314, in __call__\n    output = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 699, in __call__\n    self.build(input_shapes)\n  File \"<ipython-input-138-d8fb023f8d40>\", line 43, in build\n    trainable=True)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/base_layer.py\", line 206, in add_weight\n    trainable=trainable)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/training/checkpointable.py\", line 436, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 343, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 770, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 253, in __call__\n    shape, self.minval, self.maxval, dtype, seed=self.seed)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 674, in random_uniform\n    name=name)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/seanyu/.conda/envs/tf18_keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[256,23519360] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: wrap_pretrain/pretrain_parameters/Initializer/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _class=[\"loc:@wrap_pretrain/pretrain_parameters/Assign\"], dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](wrap_pretrain/pretrain_parameters/Initializer/random_uniform/shape)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {
    "6b1438b3075f49289cfcf03a4fce2ccb": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "ab7848b490e5454e9a42f439a6ef6b31": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "e0e3b0d66b1e47c4ade6c276bacc5c55": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
